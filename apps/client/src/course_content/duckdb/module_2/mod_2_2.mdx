# Querying Parquet Files Directly

Parquet is a columnar binary file format. Since DuckDB is a columnar database, DuckDB and Parquet are a match made in heaven.

---

## 1. Why Parquet?

1. **Smaller:** A 1GB CSV file might be only 100MB in Parquet because of compression.
2. **Typed:** Parquet files know which columns are integers and which are dates. No more "sniffing" or errors.
3. **Faster:** Because Parquet is columnar, DuckDB only reads the parts of the file it needs.

---

## 2. Using Parquet in DuckDB

You don't need to import Parquet into a database. You can just query the file as if it were a table.

```sql
SELECT brand, sum(price)
FROM 'data/products.parquet'
GROUP BY 1;
```

---

## 3. Parquet "Pushdown"

This is where the real speed comes from.

- **Projection Pushdown:** If you `SELECT name` from a Parquet file with 100 columns, DuckDB tells the hard drive: "Don't even send me the other 99 columns."
- **Filter Pushdown:** If you search for `WHERE id = 123`, DuckDB uses the metadata inside the Parquet file to skip over 99% of the file and only read the specific block where `id = 123` might exist.

---

## Real-World Example: 100GB Dataset on a Laptop

You have a dataset of 100GB of taxi trips across 500 Parquet files.

1. You only want to see the "Average Tip Amount."
2. You run: `SELECT avg(tip) FROM 'trips/*.parquet';`
3. Instead of reading 100GB, DuckDB only reads the `tip` column (maybe 2GB). It finishes the query in under 5 seconds.

---

## Hypothetical Scenario: The "S3" Secret

You have a Parquet file hosted on an Amazon S3 bucket.

- To analyze it, you would normally have to download the whole 500MB file.
- **The DuckDB Way:** DuckDB can read just the "metadata" of the file over the internet. It only downloads the specific bytes it needs for your query.
- **The Result:** You get a result for a remote file in 0.5 seconds without ever downloading the full file.

## Exercises

1. **Advantage:** Name two reasons why Parquet is better than CSV for large datasets.
2. **Syntax:** Write a SQL query to select all columns from a file named `orders.parquet`.
3. **Performance:** What is "Projection Pushdown"?

## Summary and Next Steps

Parquet is the "Gold Standard" for big data files.

But what if your data is already inside another tool, like a Python notebook? Next, we look at **DuckDB + Pandas/Arrow** and the magic of "Zero-Copy" sharing.
